{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.6"},"colab":{"name":"LabExercise4.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"CiRoFmrrth39","colab_type":"text"},"source":["# CO460 - Deep Learning - Lab exercise 4"]},{"cell_type":"markdown","metadata":{"id":"0qXvNNAsth4A","colab_type":"text"},"source":["## Introduction\n","\n","In this exercise, you will develop and experiment with convolutional AEs (CAE).\n","You will be asked to:\n","\n","- experiment with the architectures and compare the convolutional model to the fully connected one. \n","- investigate and implement sampling and interpolation in the latent space."]},{"cell_type":"code","metadata":{"id":"j0m0iPj_th4B","colab_type":"code","colab":{}},"source":["import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","from torchvision.utils import save_image \n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# utils\n","def interpolate(z1, z2, num=11):\n","    Z = np.zeros((z1.shape[0], num))\n","    for i in range(z1.shape[0]):\n","        Z[i, :] = np.linspace(z1[i], z2[i], num)\n","    return Z\n","\n","def denorm_for_tanh(x):\n","    x = 0.5 * (x + 1)\n","    x = x.clamp(0, 1)\n","    x = x.view(x.size(0), 1, 28, 28)\n","    return x\n","\n","def denorm_for_sigmoid(x):\n","    x = x.clamp(0, 1)\n","    x = x.view(x.size(0), 1, 28, 28)\n","    return x\n","\n","def denorm_for_binary(x):\n","    x = x.clamp(0, 1)\n","    x = x>0.5\n","    x = x.view(x.size(0), 1, 28, 28)\n","    return x\n","\n","def show(img):\n","    if torch.cuda.is_available():\n","        img = img.cpu()\n","    npimg = img.numpy()\n","    plt.imshow(np.transpose(npimg, (1,2,0)))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mJK7rs6Vth4F","colab_type":"text"},"source":["### Device selection"]},{"cell_type":"code","metadata":{"id":"suo8Sr7nth4G","colab_type":"code","colab":{}},"source":["GPU = True\n","device_idx = 0\n","if GPU:\n","    device = torch.device(\"cuda:\"+str(device_idx) if torch.cuda.is_available() else \"cpu\")\n","else:\n","    \n","    device = torch.device(\"cpu\")\n","print(device)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oNK0PfA1th4J","colab_type":"text"},"source":["### Reproducibility"]},{"cell_type":"code","metadata":{"id":"DKZmjRX5th4K","colab_type":"code","colab":{}},"source":["# We set a random seed to ensure that your results are reproducible.\n","if torch.cuda.is_available():\n","    torch.backends.cudnn.deterministic = True\n","torch.manual_seed(0)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"53GNQz0Ath4S","colab_type":"text"},"source":["### Normalization: \n","$ x_{norm} = \\frac{x-\\mu}{\\sigma} $\n","\n","_Thus_ :\n","$ \\min{x_{norm}} = \\frac{\\min{(x)}-\\mu}{\\sigma} = \\frac{0-0.5}{0.5} = -1 $\n","\n","_Similarly_:\n","\n","$ \\max{(x_{norm})} = ... = 1 $\n","\n","\n","* Input $\\in [-1,1] $\n","* Output should span the same interval $ \\rightarrow$ Activation function of the output layer should be chosen carfeully (Here??)"]},{"cell_type":"code","metadata":{"id":"4CZ5-DzWth4T","colab_type":"code","colab":{}},"source":["transform = transforms.Compose([\n","     transforms.ToTensor(),\n","     transforms.Normalize((0.5,), (0.5,))\n","])\n","\n","denorm = denorm_for_tanh\n","\n","train_dat = datasets.MNIST(\n","    \"data/\", train=True, download=True, transform=transform\n",")\n","test_dat = datasets.MNIST(\"data/\", train=False, transform=transform)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xNY_msKEth4W","colab_type":"text"},"source":["### Hyper-parameter selection"]},{"cell_type":"code","metadata":{"id":"4fLKZ1hLth4X","colab_type":"code","colab":{}},"source":["if not os.path.exists('./CAE'):\n","    os.mkdir('./CAE')\n","    \n","num_epochs = 20\n","batch_size = 128\n","learning_rate = 1e-3"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ln3oss5Qth4b","colab_type":"text"},"source":["### Define the dataloaders"]},{"cell_type":"code","metadata":{"id":"N6XYl3eCth4c","colab_type":"code","colab":{}},"source":["train_loader = DataLoader(train_dat, batch_size, shuffle=True)\n","test_loader = DataLoader(test_dat, batch_size, shuffle=False)\n","\n","it = iter(test_loader)\n","sample_inputs, _ = next(it)\n","fixed_input = sample_inputs[:32, :, :, :]\n","\n","in_dim = fixed_input.shape[-1]*fixed_input.shape[-2]\n","\n","save_image(fixed_input, './CAE/image_original.png')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uH5SWbiyth4f","colab_type":"text"},"source":["### Define the model - CAE\n","\n","Complete the `encoder` and `decoder` methods in the CAE pipeline.\n","\n","To find an effective architecture, you can experiment with the following:\n","- the number of convolutional layers\n","- the kernels' sizes\n","- the stride values\n","- the size of the latent space layer"]},{"cell_type":"code","metadata":{"id":"Jr9Af9ipth4g","colab_type":"code","colab":{}},"source":["class CAE(nn.Module):\n","    def __init__(self, latent_dim):\n","        super(CAE, self).__init__()\n","        \"\"\"\n","        TODO: Define here the layers (convolutions, relu etc.) that will be\n","        used in the encoder and decoder pipelines.\n","        \"\"\"\n","        \n","        \n","    def encode(self, x):\n","        \"\"\"\n","        TODO: Construct the encoder pipeline here. The encoder's\n","        output will be the laten space representation of x.\n","        \n","        \"\"\"\n","        \n","        return x\n","    \n","    def decode(self, z):\n","        \"\"\"\n","        TODO: Construct the decoder pipeline here. The decoder should \n","        generate an output tensor with equal dimenssions to the\n","        encoder's input tensor.\n","        \n","        \"\"\"\n","        \n","        return z\n","\n","    def forward(self, x):\n","        x = self.encoder(x)\n","        x = self.decoder(x)\n","        return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YV9q7bvpth4j","colab_type":"code","colab":{}},"source":["# Instantiate the model\n","latent_dim = \n","cv_AE = CAE(latent_dim=latent_dim)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Pti8rNBTth4m","colab_type":"text"},"source":["### Define Loss function"]},{"cell_type":"code","metadata":{"id":"2ldiQPHdth4n","colab_type":"code","colab":{}},"source":["criterion = nn.L1Loss(reduction='sum')  # can we use any other loss here?\n","def loss_function_CAE(recon_x, x):\n","    recon_loss = criterion(recon_x, x)\n","    return recon_loss"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L2myUtf4th4q","colab_type":"text"},"source":["### Initialize Model and print number of parameters"]},{"cell_type":"code","metadata":{"id":"qP8jvfsqth4r","colab_type":"code","colab":{}},"source":["model = cv_AE.to(device)\n","params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","print(\"Total number of parameters is: {}\".format(params))  # what would the number actually be?\n","print(model)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FCNjyIEJth4u","colab_type":"text"},"source":["### Choose and initialize optimizer"]},{"cell_type":"code","metadata":{"id":"4tr4ztEEth4v","colab_type":"code","colab":{}},"source":["optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6h2Rqk8Tth4z","colab_type":"text"},"source":["### Train"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"Nuq-zfw7th40","colab_type":"code","colab":{}},"source":["model.train()\n","\n","for epoch in range(num_epochs):\n","    train_loss = 0\n","    for batch_idx, data in enumerate(train_loader):\n","        img, _ = data\n","        img = img.to(device)\n","        optimizer.zero_grad()\n","        # forward\n","        recon_batch = model(img)\n","        loss = loss_function_CAE(recon_batch, img)\n","        # backward\n","        loss.backward()\n","        train_loss += loss.item()\n","        optimizer.step()\n","    # print out losses and save reconstructions for every epoch\n","    print('epoch [{}/{}], loss:{:.4f}'.format(epoch + 1, num_epochs, train_loss / len(train_loader.dataset)))\n","    recon = denorm(model(fixed_input.to(device)))\n","    save_image(recon.float(), './CAE/reconstructed_epoch_{}.png'.format(epoch))\n","\n","# save the model\n","torch.save(model.state_dict(), './CAE/model.pth')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XaJFHh-Cth43","colab_type":"text"},"source":["### Test"]},{"cell_type":"code","metadata":{"id":"lKnepQY8th43","colab_type":"code","colab":{}},"source":["# load the model\n","model.load_state_dict(torch.load(\"./CAE/model.pth\"))\n","model.eval()\n","test_loss = 0\n","with torch.no_grad():\n","    for i, (img, _) in enumerate(test_loader):\n","        img = img.to(device)\n","        recon_batch = model(img)\n","        test_loss += loss_function_CAE(recon_batch, img)\n","    # reconstruct and save the last batch\n","    recon_batch = model(recon_batch.to(device))\n","    img = denorm(img.cpu())\n","    # save the original last batch\n","    save_image(img.float(), './CAE/test_original.png')\n","    save_image(denorm(recon_batch.cpu()).float(), './CAE/reconstructed_test.png')\n","    # loss calculated over the whole test set\n","    test_loss /= len(test_loader.dataset)\n","    print('Test set loss: {:.4f}'.format(test_loss))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jxwzm9pIth46","colab_type":"text"},"source":["### Interpolations"]},{"cell_type":"code","metadata":{"id":"I5NqKdO8th47","colab_type":"code","colab":{}},"source":["# Define inpute tensors\n","x1 = \n","x2 = \n","\n","# Create the latent representations\n","z1 = model.encode(x1)\n","z2 = model.encode(x2)\n","\n","\"\"\"\n","TODO: Find a way to create interpolated results from the CAE.\n","\"\"\"\n","Z = \n","X_hat = model.decode(Z)"],"execution_count":0,"outputs":[]}]}