{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"colab":{"name":"LabExercise5.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"HXrDZvoyuArF","colab_type":"text"},"source":["# CO460 - Deep Learning - Lab exercise 5"]},{"cell_type":"markdown","metadata":{"id":"pt7Z-sMWuArI","colab_type":"text"},"source":["## Introduction\n","\n","In this exercise, you will experiment with a GAN and a Conditional GAN architecture.\n","You are asked to:\n","\n","1.  Experiment with the architectures\n","2.  Define the training strategy\n","3.  Investigate and implement sampling and interpolation in the latent space."]},{"cell_type":"code","metadata":{"id":"MEVUTiD1uArJ","colab_type":"code","colab":{}},"source":["import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","from torchvision.utils import save_image, make_grid\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# utils\n","def interpolate(z1, z2, num=11):\n","    Z = np.zeros((z1.shape[0], num))\n","    for i in range(z1.shape[0]):\n","        Z[i, :] = np.linspace(z1[i], z2[i], num)\n","    return Z\n","\n","def denorm_for_tanh(x):\n","    x = 0.5 * (x + 1)\n","    x = x.clamp(0, 1)\n","    x = x.view(x.size(0), 1, 28, 28)\n","    return x\n","\n","def denorm_for_sigmoid(x):\n","    x = x.clamp(0, 1)\n","    x = x.view(x.size(0), 1, 28, 28)\n","    return x\n","\n","def denorm_for_binary(x):\n","    x = x.clamp(0, 1)\n","    x = x>0.5\n","    x = x.view(x.size(0), 1, 28, 28)\n","    return x\n","\n","def show(img):\n","    if torch.cuda.is_available():\n","        img = img.cpu()\n","    npimg = img.numpy()\n","    plt.imshow(np.transpose(npimg, (1,2,0)))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U7AsVR5FuArN","colab_type":"text"},"source":["### Device selection"]},{"cell_type":"code","metadata":{"id":"1AwdX98CuArO","colab_type":"code","outputId":"6433dd77-8a11-4c29-dace-a73bf4e26aa8","colab":{}},"source":["GPU = True\n","device_idx = 0\n","if GPU:\n","    device = torch.device(\"cuda:\" + str(device_idx) if torch.cuda.is_available() else \"cpu\")\n","else:\n","    device = torch.device(\"cpu\")\n","print(device)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["cuda:0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pBTTznT3uArS","colab_type":"text"},"source":["### Reproducibility"]},{"cell_type":"code","metadata":{"id":"FnSVtUzIuArT","colab_type":"code","outputId":"5c1d6143-39cb-4467-ae94-899d3eb049e0","colab":{}},"source":["# We set a random seed to ensure that your results are reproducible.\n","if torch.cuda.is_available():\n","    torch.backends.cudnn.deterministic = True\n","torch.manual_seed(0)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f9453928eb0>"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"jjTr_4JruArX","colab_type":"code","colab":{}},"source":["transform = transforms.Compose([\n","     transforms.ToTensor(),\n","     transforms.Normalize(mean=(0.5,), std=(0.5,))\n","])\n","\n","train_dat = datasets.MNIST(\n","    \"data/\", train=True, download=True, transform=transform\n",")\n","test_dat = datasets.MNIST(\"./data/\", train=False, transform=transform)\n","\n","denorm = denorm_for_tanh\n","\n","if not os.path.exists('./cGAN'):\n","    os.mkdir('./cGAN')\n","    \n","if not os.path.exists('./GAN'):\n","    os.mkdir('./GAN')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zWPp7fj1uAra","colab_type":"text"},"source":["### Hyper-parameter selection"]},{"cell_type":"code","metadata":{"id":"RtMqeDYbuArb","colab_type":"code","colab":{}},"source":["\"\"\"\n","TODO: Define here your hyperparameters\n","\"\"\"\n","\n","num_epochs = None\n","batch_size = None\n","learning_rate = None\n","noise_dim = None\n","\n","\n","in_dim = np.prod(train_dat[0][0].shape)\n","out_shape = train_dat[0][0].shape\n","sample_interval = 5"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"AE6IFmd-uArf","colab_type":"code","colab":{}},"source":["train_loader = DataLoader(train_dat, batch_size, shuffle=True, num_workers=16)\n","test_loader = DataLoader(test_dat, batch_size, shuffle=False, num_workers=16)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ln94JaLfuAri","colab_type":"text"},"source":["### Define the model"]},{"cell_type":"code","metadata":{"id":"oAhM77-juArj","colab_type":"code","colab":{}},"source":["class Generator(torch.nn.Module):\n","\n","    def __init__(self):\n","        super(Generator, self).__init__()\n","        \"\"\"\n","        TODO: Layer definitions for the Generator\n","        \"\"\"\n","        \n","    def forward(self, x):\n","    \n","        \"\"\"\n","        TODO: Generator pipeline. Your output should have the same dimensions as the real images\n","        \"\"\"\n","            \n","        return x\n","    \n","\n","class Discriminator(torch.nn.Module):\n","\n","    def __init__(self):\n","        super(Discriminator, self).__init__()\n","        \"\"\"\n","        TODO: Layer definitions for the Discriminator\n","        \"\"\"\n","\n","    def forward(self, x):\n","        \"\"\"\n","        TODO: Discriminator pipeline. Your output should have only one dimension.\n","        \"\"\"\n","            \n","        return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IdqIAwoxuArn","colab_type":"code","colab":{}},"source":["generator = Generator()\n","discriminator = Discriminator()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jYpeRqj9uArq","colab_type":"text"},"source":["### Define Loss function"]},{"cell_type":"code","metadata":{"id":"Zy03MXnAuArr","colab_type":"code","colab":{}},"source":["criterion = nn.BCELoss(reduction='mean')\n","def loss_function(out, label):\n","    loss = criterion(out, label)\n","    return loss"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yyOl15G7uAru","colab_type":"text"},"source":["### Initialize Model and print number of parameters"]},{"cell_type":"code","metadata":{"id":"ZJL95NnOuArv","colab_type":"code","colab":{}},"source":["generator = generator.to(device)\n","discriminator = discriminator.to(device)\n","\n","params = sum(p.numel() for p in generator.parameters() if p.requires_grad)\n","print(\"Total number of generator parameters is: {}\".format(params))  # what would the number actually be\n","print(generator)\n","\n","params = sum(p.numel() for p in discriminator.parameters() if p.requires_grad)\n","print(\"Total number of discriminator parameters is: {}\".format(params))  # what would the number actually be\n","print(discriminator)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yiqpSNQTuAry","colab_type":"text"},"source":["### Choose and initialize optimizer"]},{"cell_type":"code","metadata":{"id":"q8d-DpK2uArz","colab_type":"code","colab":{}},"source":["optimizer_G = torch.optim.Adam(generator.parameters(), lr=learning_rate)\n","optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=learning_rate)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UlmN95KouAr2","colab_type":"text"},"source":["### Pick a noise distribution"]},{"cell_type":"code","metadata":{"id":"Ghga3lKluAr3","colab_type":"code","colab":{}},"source":["def generate_noise(batch_size, noise_dim):\n","    \"\"\"\n","    TODO: Define here your noise distribution (probably gaussian or uniform)\n","    \"\"\"\n","    return noise                        "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a21eyrryuAr7","colab_type":"text"},"source":[" ### Train"]},{"cell_type":"code","metadata":{"id":"EhYBpf-1uAr8","colab_type":"code","colab":{}},"source":["g_losses = []\n","d_losses = []\n","generator.train()\n","discriminator.train()\n","num_epochs = 200 \n","fixed_noise = generate_noise(batch_size, noise_dim)\n","\n","for epoch in range(num_epochs):\n","    g_loss_epoch = 0\n","    d_loss_epoch = 0 \n","    for batch_idx, data in enumerate(train_loader):\n","        \n","        \"\"\"\n","        TODO: Define here your training strategy\n","        \"\"\"\n","        d_loss_epoch += d_loss.item()\n","        g_loss_epoch += g_loss.item()\n","\n","\n","    print('epoch [{}/{}], generator loss:{:.4f}'\n","          .format(epoch + 1, num_epochs, g_loss_epoch / len(train_loader)))\n","    g_losses.append(g_loss_epoch/ len(train_loader))\n","    print('epoch [{}/{}], discriminator loss:{:.4f}'\n","          .format(epoch + 1, num_epochs, d_loss_epoch / len(train_loader)))\n","    d_losses.append(d_loss_epoch/ len(train_loader))\n","    if epoch % sample_interval == 0:\n","        save_image(denorm(generator(fixed_noise.to(device))).cpu().float(), './GAN/samples_epoch_{}.png'.format(epoch),nrow = 8)\n","    torch.save(generator.state_dict(), './GAN/generator.pth')\n","    torch.save(discriminator.state_dict(), './GAN/discriminator.pth')\n","    \n","np.save('./GAN/generator_losses.npy', np.array(g_losses))\n","np.save('./GAN/discriminator_losses.npy', np.array(d_losses))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jTOOtqxduAr_","colab_type":"text"},"source":["### Loss curves"]},{"cell_type":"code","metadata":{"id":"xNTJWgVauAsA","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","generator_losses = np.load('./GAN/generator_losses.npy')\n","plt.plot(list(range(0,generator_losses.shape[0])), generator_losses)\n","plt.title('Generator Loss')\n","plt.show()\n","\n","import matplotlib.pyplot as plt\n","discriminator_losses = np.load('./GAN/discriminator_losses.npy')\n","plt.plot(list(range(0,discriminator_losses.shape[0])), discriminator_losses)\n","plt.title('Discriminator Loss')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gLfx-SUDuAsF","colab_type":"text"},"source":["### Sampling"]},{"cell_type":"code","metadata":{"id":"Wc-VGXjwuAsG","colab_type":"code","colab":{}},"source":["generator.load_state_dict(torch.load(\"./GAN/generator.pth\"))\n","\n","\"\"\"\n","TODO: Sample from the noise distribution\n","\"\"\"\n","\n","\"\"\"\n","TODO: Do a linear interpolation in the latent space between two noise vectors \n","      and generate all the intermediate samples\n","\"\"\"\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O2OLRT9AuAsJ","colab_type":"text"},"source":["## Conditional GAN"]},{"cell_type":"markdown","metadata":{"id":"k2UHb5tsuAsJ","colab_type":"text"},"source":["The concept of conditional GAN: \n","\n","* $\\mathbf{x}$ refers to a train datum\n","* $\\mathbf{y}$ refers to the corresponding label\n","* $\\mathbf{z}$ refers to random noise vector\n","<img src=\"./imgs/cGAN.png\" width=\"500\" />"]},{"cell_type":"markdown","metadata":{"id":"vbX6Kj2nuAsK","colab_type":"text"},"source":["### Hyper-parameter selection"]},{"cell_type":"code","metadata":{"id":"Jmg8syDhuAsL","colab_type":"code","colab":{}},"source":["\"\"\"\n","TODO: Define here your hyperparameters\n","\"\"\"\n","\n","num_epochs = None\n","batch_size = None\n","learning_rate = None\n","\n","num_workers = 16\n","num_classes = 10\n","sample_interval = 5"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2krBUITpuAsO","colab_type":"text"},"source":["### Define the dataloaders"]},{"cell_type":"code","metadata":{"id":"xCkvkDKruAsP","colab_type":"code","colab":{}},"source":["train_loader = DataLoader(train_dat, batch_size, shuffle=True, num_workers=num_workers)\n","test_loader = DataLoader(test_dat, batch_size, shuffle=False, num_workers=num_workers)\n","total_step = len(train_loader)\n","\n","it = iter(test_loader)\n","sample_inputs, _ = next(it)\n","\n","in_dim = sample_inputs.shape[-1] * sample_inputs.shape[-2]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YV_xMwOBuAsS","colab_type":"text"},"source":["### Define the Generator and the Discriminator"]},{"cell_type":"code","metadata":{"id":"s9LW8e8YuAsS","colab_type":"code","colab":{}},"source":["class Generator(torch.nn.Module):\n","\n","    def __init__(self):\n","        super(Generator, self).__init__()\n","        \"\"\"\n","        TODO: Layer definitions for the Generator\n","        \"\"\"\n","        \n","    def forward(self, x):\n","    \n","        \"\"\"\n","        TODO: Generator pipeline. Your output should have the same dimensions as the real images\n","        \"\"\"\n","            \n","        return x\n","    \n","  \n","class Discriminator(torch.nn.Module):\n","\n","    def __init__(self):\n","        super(Discriminator, self).__init__()\n","        \"\"\"\n","        TODO: Layer definitions for the Discriminator\n","        \"\"\"\n","\n","    def forward(self, x):\n","        \"\"\"\n","        TODO: Discriminator pipeline. Your output should have only one dimension.\n","        \"\"\"\n","            \n","        return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ySMjupjvuAsV","colab_type":"code","colab":{}},"source":["generator = Generator(latent_dim, in_dim)\n","discriminator = Discriminator(in_dim)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DrlEHAlsuAsX","colab_type":"text"},"source":["### Define loss function"]},{"cell_type":"code","metadata":{"id":"V00YoBLQuAsY","colab_type":"code","colab":{}},"source":["criterion = nn.BCELoss(reduction='mean')\n","def loss_function(out, label):\n","    loss = criterion(out, label)\n","    return loss"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7qQ1wyFguAsb","colab_type":"text"},"source":["### Initialize Model and print number of parameters for both G and D"]},{"cell_type":"code","metadata":{"id":"9AYdlqhluAsc","colab_type":"code","colab":{}},"source":["generator = generator.to(device)\n","discriminator = discriminator.to(device)\n","g_params = sum(p.numel() for p in generator.parameters() if p.requires_grad)\n","d_params = sum(p.numel() for p in discriminator.parameters() if p.requires_grad)\n","print(\"The number of parameters for G is: {}\".format(g_params))\n","print(\"The number of parameters for D is: {}\".format(d_params))\n","print(\"The total number of parameters is: {}\".format(g_params + d_params))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GEYh1QRQuAse","colab_type":"text"},"source":["### Choose and initialize optimizer"]},{"cell_type":"code","metadata":{"id":"fidt6bPSuAsf","colab_type":"code","colab":{}},"source":["g_optimizer = torch.optim.Adam(generator.parameters(), lr=learning_rate)\n","d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=learning_rate)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lLEdU4mVuAsi","colab_type":"text"},"source":["### Train"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"yl6kikmJuAsj","colab_type":"code","colab":{}},"source":["generator.train()\n","discriminator.train()\n","g_losses = []\n","d_losses = []\n","\n","fixed_noise = torch.rand(num_classes, latent_dim).to(device)\n","fixed_labels = np.arange(num_classes)\n","fixed_labels = (torch.from_numpy(fixed_labels)).type(torch.LongTensor)\n","fixed_labels = fixed_labels.to(device)\n","fixed_labels_one_hot = torch.zeros(num_classes, num_classes).to(device)\n","fixed_labels_one_hot.scatter_(1, fixed_labels.view(num_classes, 1), 1)\n","\n","for epoch in range(num_epochs):\n","    g_loss_epoch = 0\n","    d_loss_epoch = 0\n","    \n","    for batch_idx, (images, labels) in enumerate(train_loader):\n","        batch_size = images.size(0)\n","\n","        \"\"\"\n","        TODO: Define here your training strategy\n","        \"\"\"\n","        \n","        d_loss_epoch += d_loss.item()\n","        g_loss_epoch += g_loss.item()\n","        \n","    print('epoch [{}/{}], generator loss:{:.4f}'\n","          .format(epoch + 1, num_epochs, g_loss_epoch / len(train_loader)))\n","    g_losses.append(g_loss_epoch/ len(train_loader))\n","    print('epoch [{}/{}], discriminator loss:{:.4f}'\n","          .format(epoch + 1, num_epochs, d_loss_epoch / len(train_loader)))\n","    d_losses.append(d_loss_epoch/ len(train_loader))\n","    if epoch % sample_interval == 0:\n","        fake_fixed_images = generator(fixed_noise, fixed_labels_one_hot)\n","        fake_fixed_images = denorm(fake_fixed_images)\n","        save_image(fake_fixed_images.cpu().float(), './cGAN/samples_epoch_{}.png'.format(epoch),nrow = 8)\n","    torch.save(generator.state_dict(), './cGAN/generator.pth')\n","    torch.save(discriminator.state_dict(), './cGAN/discriminator.pth')\n","    \n","np.save('./cGAN/generator_losses.npy', np.array(g_losses))\n","np.save('./cGAN/discriminator_losses.npy', np.array(d_losses))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zuLObH7QuAsm","colab_type":"text"},"source":["### Loss curves"]},{"cell_type":"code","metadata":{"id":"_bpMqAhIuAsn","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","generator_losses = np.load('./cGAN/generator_losses.npy')\n","plt.plot(list(range(0,generator_losses.shape[0])), generator_losses)\n","plt.title('Generator Loss')\n","plt.show()\n","\n","import matplotlib.pyplot as plt\n","discriminator_losses = np.load('./cGAN/discriminator_losses.npy')\n","plt.plot(list(range(0,discriminator_losses.shape[0])), discriminator_losses)\n","plt.title('Discriminator Loss')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bsHCboaLuAsq","colab_type":"text"},"source":["### Sampling"]},{"cell_type":"code","metadata":{"id":"I39pk9o2uAsr","colab_type":"code","colab":{}},"source":["generator.load_state_dict(torch.load(\"./cGAN/generator.pth\"))\n","\n","\"\"\"\n","TODO: Sample from the noise distribution\n","\"\"\"\n"],"execution_count":0,"outputs":[]}]}